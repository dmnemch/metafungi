{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be52df5d-d1ac-4e26-a4b3-9beeeee6579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94a0a6c7-d2b9-4fa8-9230-8a0fc8d16915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cat(sample, path, taxa, contig_min_len, orf_min_percentage):\n",
    "    tsv_base = f'{path}/cat/{sample}/{sample}_classification'\n",
    "        with open(f'{tsv_base}.tsv', 'r') as f, open(f'{tsv_base}.refined.tsv', 'w') as out:\n",
    "        for line in f:\n",
    "            if len(line.split('\\t')) == 12:\n",
    "                print(line, file=out)\n",
    "    data = pd.read_csv(f'{tsv_base}.refined.tsv', sep=\"\\t\")\n",
    "    data = data[(data['# contig'].str.extract('NODE_\\d+_length_(\\d+)_cov_.+').astype('int') >= contig_min_len)[0]]\n",
    "    data = data[(data.reason.str.extract('based on (\\d+)/\\d+ ORFs').astype(int)/data.reason.str.extract('based on \\d+/(\\d+) ORFs').astype(int) >= orf_min_percentage)[0]]\n",
    "    for taxon in taxa:\n",
    "        data = data[data.lineage.str.contains(str(taxon))]\n",
    "    data['sample'] = sample\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_cat(samples, path, taxa=[4751], contig_min_len=1000, orf_min_percentage=0.2):\n",
    "    all_data = pd.DataFrame(columns=['# contig', 'classification', 'reason', 'lineage', 'lineage scores',\n",
    "       'superkingdom', 'phylum', 'class', 'order', 'family', 'genus',\n",
    "       'species', 'sample'])\n",
    "    \n",
    "    for sample in samples:\n",
    "        data = filter_cat(sample=sample, taxa=taxa, contig_min_len=contig_min_len, orf_min_percentage=orf_min_percentage, path=path)\n",
    "        all_data = pd.concat([all_data, data])\n",
    "\n",
    "    genus_counts = all_data[['sample', 'genus']].copy()\n",
    "    genus_counts['counts'] = genus_counts['genus'].str.split(':').str[1].astype(float)\n",
    "    genus_counts = genus_counts.groupby(['sample', 'genus']).agg({'counts': 'sum'}).reset_index()\n",
    "    genus_counts['genus'] = genus_counts['genus'].str.replace(': 1.00', '').str.strip()\n",
    "    genus_counts['counts'] = genus_counts['counts'].astype(int)\n",
    "    genus_counts['tool'] = 'cat'\n",
    "    \n",
    "    return genus_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40e5c10-f95f-45e5-bf6a-218c703f4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_its(sample, path):\n",
    "    base = f'{path}/V350174473_L01_UDB-{sample}_UNITE_public_10.05.2021.sorted.bam'\n",
    "    bam_file = pysam.AlignmentFile(base, 'rb')\n",
    "    samples = []\n",
    "    genus_list = []\n",
    "    counts_list = []\n",
    "\n",
    "    for read in bam_file:\n",
    "        reference_name = read.reference_name\n",
    "        genus = reference_name.split('g__')[1].split(';')[0]\n",
    "        samples.append(sample)\n",
    "        genus_list.append(genus)\n",
    "        counts_list.append(1)\n",
    "    bam_file.close()\n",
    "\n",
    "    data = {'sample': samples, 'genus': genus_list, 'counts': counts_list}\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.groupby(['sample', 'genus']).agg({'counts': 'sum'}).reset_index()\n",
    "    return df\n",
    "\n",
    "def process_its(samples, path):\n",
    "    all_data = pd.DataFrame(columns=[\"sample\", \"genus\", \"counts\"])\n",
    "    for sample in samples:\n",
    "        df = filter_its(sample, path)\n",
    "        all_data = pd.concat([all_data, df])\n",
    "    all_data['tool'] = 'its'\n",
    "    all_data = all_data.reset_index(drop=True)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "10065ff1-9514-4bf2-8686-1ffafe13551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_kraken(sample, path, n_top=10000):\n",
    "    report = f'{path}/V350174473_L01_UDB-{sample}_report.txt'\n",
    "    df = pd.read_csv(report, delimiter=\"\\t\", names=[\"perc\", \"counts\", \"only_reads\", \"rank\", \"taxid\", \"genus\"])\n",
    "\n",
    "    include_rows = False\n",
    "    filtered_rows = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row['taxid'] == 4751:\n",
    "            include_rows = True\n",
    "            continue\n",
    "        if row['rank'] == 'D1':\n",
    "            include_rows = False\n",
    "        elif row['rank'] == 'G' and include_rows:\n",
    "            filtered_rows.append(row)\n",
    "\n",
    "    filtered_df = pd.DataFrame(filtered_rows)\n",
    "    filtered_df[\"sample\"] = sample\n",
    "    filtered_df = filtered_df[[\"sample\", \"genus\", \"counts\"]].sort_values(by=\"counts\", ascending=False).reset_index(drop=True)\n",
    "    filtered_df[\"tool\"] = \"kraken2\"\n",
    "    return filtered_df\n",
    "\n",
    "def process_kraken(samples, path):\n",
    "    all_data = pd.DataFrame(columns=[\"sample\", \"genus\", \"counts\"])\n",
    "    for sample in samples:\n",
    "        df = filter_kraken(sample, path)\n",
    "        all_data = pd.concat([all_data, df])\n",
    "    all_data = all_data.reset_index(drop=True)\n",
    "    return all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
